{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfmhplaZHjQj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('chatgpt.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FATddku9Hpqp",
        "outputId": "ddd794c4-d290-4b88-eb2b-bae38586e109"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e7b41038-c07f-403d-aa6b-721740216a70\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Try talking with ChatGPT, our new AI system wh...</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>THRILLED to share that ChatGPT, our new model ...</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>As of 2 minutes ago, @OpenAI released their ne...</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7b41038-c07f-403d-aa6b-721740216a70')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7b41038-c07f-403d-aa6b-721740216a70 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7b41038-c07f-403d-aa6b-721740216a70');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0                                             tweets   labels\n",
              "0           0  ChatGPT: Optimizing Language Models for Dialog...  neutral\n",
              "1           1  Try talking with ChatGPT, our new AI system wh...     good\n",
              "2           2  ChatGPT: Optimizing Language Models for Dialog...  neutral\n",
              "3           3  THRILLED to share that ChatGPT, our new model ...     good\n",
              "4           4  As of 2 minutes ago, @OpenAI released their ne...      bad"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "ApYrdSobZZu4",
        "outputId": "c0b71a3d-2c5a-4c0e-da20-d82ead3f4d6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(df['labels'], color = 'gray')\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFidaOA9Bi5c",
        "outputId": "9a856964-2722-4e6f-8cd1-724a827a5be2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(219294, 3)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPROCESSING"
      ],
      "metadata": {
        "id": "fSOOVj6IGv3v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3qLeh2nHseR",
        "outputId": "4cc59390-4f43-402a-a802-54196991f46e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "my_stemmer = PorterStemmer()\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "num_reviews = df['tweets'].size\n",
        "nltk.download('punkt')\n",
        "\n",
        "def preprocessor(raw_review):\n",
        "    clean1 = re.sub(r'http\\S+', ' ', raw_review)\n",
        "    clean2 = re.sub(r'www\\S+', ' ', clean1)\n",
        "    clean3 = re.sub(r'@\\w+', ' ', clean2)\n",
        "    clean4 = re.sub(r'#\\w+', ' ', clean3)\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean4)\n",
        "    words = word_tokenize(letters_only.lower())\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    meaningful_words = [w for w in words if not w in stops]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in meaningful_words]\n",
        "    # return \" \".join(lemmatized_words)\n",
        "    return lemmatized_words\n",
        "\n",
        "\n",
        "df['tokenized'] = df['tweets'].apply(preprocessor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "BUJk8wPhkvIZ",
        "outputId": "e20ddbac-a314-4fe3-d547-7c7f1a576dc0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-398dc599-dc70-43ed-a230-6b5748609497\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[chatgpt, optimizing, language, model, dialogue]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Try talking with ChatGPT, our new AI system wh...</td>\n",
              "      <td>good</td>\n",
              "      <td>[try, talking, chatgpt, new, ai, system, optim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[chatgpt, optimizing, language, model, dialogu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>THRILLED to share that ChatGPT, our new model ...</td>\n",
              "      <td>good</td>\n",
              "      <td>[thrilled, share, chatgpt, new, model, optimiz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>As of 2 minutes ago, @OpenAI released their ne...</td>\n",
              "      <td>bad</td>\n",
              "      <td>[minute, ago, released, new, chatgpt, n, nand,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-398dc599-dc70-43ed-a230-6b5748609497')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-398dc599-dc70-43ed-a230-6b5748609497 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-398dc599-dc70-43ed-a230-6b5748609497');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0                                             tweets   labels  \\\n",
              "0           0  ChatGPT: Optimizing Language Models for Dialog...  neutral   \n",
              "1           1  Try talking with ChatGPT, our new AI system wh...     good   \n",
              "2           2  ChatGPT: Optimizing Language Models for Dialog...  neutral   \n",
              "3           3  THRILLED to share that ChatGPT, our new model ...     good   \n",
              "4           4  As of 2 minutes ago, @OpenAI released their ne...      bad   \n",
              "\n",
              "                                           tokenized  \n",
              "0   [chatgpt, optimizing, language, model, dialogue]  \n",
              "1  [try, talking, chatgpt, new, ai, system, optim...  \n",
              "2  [chatgpt, optimizing, language, model, dialogu...  \n",
              "3  [thrilled, share, chatgpt, new, model, optimiz...  \n",
              "4  [minute, ago, released, new, chatgpt, n, nand,...  "
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "def preprocess_data(df):\n",
        "    word_counts = defaultdict(int)\n",
        "    label_counts = defaultdict(int)\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        label, text = row['labels'], row['tokenized']\n",
        "\n",
        "        # Add POS tagging\n",
        "        pos_tags = pos_tag(text)\n",
        "\n",
        "        label_counts[label] += 1\n",
        "        for word, pos_tag in pos_tags:\n",
        "            word_counts[(word, pos_tag)] += 1  # Store word and its POS tag\n",
        "\n",
        "    return word_counts, label_counts\n",
        "def train_hmm(word_counts, label_counts):\n",
        "    initial_probs = {}\n",
        "    transition_probs = defaultdict(lambda: defaultdict(int))\n",
        "    emission_probs = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    total_labels = sum(label_counts.values())\n",
        "\n",
        "    for label, count in label_counts.items():\n",
        "        initial_probs[label] = count / total_labels\n",
        "\n",
        "    for word_pos, count in word_counts.items():\n",
        "        word, pos_tag = word_pos\n",
        "\n",
        "        for label in label_counts.keys():\n",
        "            transition_probs[label][word_pos] = count / label_counts[label]\n",
        "\n",
        "        total_emissions = sum(transition_probs[label].values())\n",
        "        for word_pos in transition_probs[label].keys():\n",
        "            emission_probs[label][word_pos] = transition_probs[label][word_pos] / total_emissions\n",
        "\n",
        "    return initial_probs, transition_probs, emission_probs\n",
        "\n",
        "def viterbi(tweet, initial_probs, transition_probs, emission_probs):\n",
        "    if len(tweet) == 0:\n",
        "        return []\n",
        "\n",
        "    T = len(tweet)\n",
        "    N = len(sentiment_labels)\n",
        "\n",
        "    trellis = np.zeros((N, T))\n",
        "    backpointers = np.zeros((N, T), dtype=int)\n",
        "\n",
        "    for s in range(N):\n",
        "        trellis[s, 0] = initial_probs[sentiment_labels[s]] * emission_probs[sentiment_labels[s]][(tweet[0], pos_tag[0])]\n",
        "\n",
        "    for t in range(1, T):\n",
        "        for s in range(N):\n",
        "            max_prob = 0\n",
        "            max_state = 0\n",
        "            for prev_s in range(N):\n",
        "                prob = trellis[prev_s, t-1] * transition_probs[sentiment_labels[prev_s]][(tweet[t], pos_tag[t])] * emission_probs[sentiment_labels[s]][(tweet[t], pos_tag[t])]\n",
        "                if prob > max_prob:\n",
        "                    max_prob = prob\n",
        "                    max_state = prev_s\n",
        "            trellis[s, t] = max_prob\n",
        "            backpointers[s, t] = max_state\n",
        "\n",
        "    path = np.zeros(T, dtype=int)\n",
        "    path[T-1] = np.argmax(trellis[:, T-1])\n",
        "    for t in range(T-2, -1, -1):\n",
        "        path[t] = backpointers[path[t+1], t+1]\n",
        "\n",
        "    predicted_labels = [sentiment_labels[state] for state in path]\n",
        "    return predicted_labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2ThSdxdRXTO",
        "outputId": "454e174e-92ef-4b29-b599-20875bd554c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = df.sample(frac=0.8, random_state=1)\n",
        "test_df = df.drop(train_df.index)\n"
      ],
      "metadata": {
        "id": "xkqqZHVBRyal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[:100000]"
      ],
      "metadata": {
        "id": "Zv-4H2APascf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag as pt\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "sentiment_labels = ['good', 'bad', 'neutral']\n",
        "\n",
        "initial_probs = {}\n",
        "transition_probs = defaultdict(lambda: defaultdict(int))\n",
        "emission_probs = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "def preprocess_data(df):\n",
        "    word_counts = defaultdict(int)\n",
        "    label_counts = defaultdict(int)\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        label, text = row['labels'], row['tokenized']\n",
        "\n",
        "        pos_tags = pt(text)\n",
        "\n",
        "        label_counts[label] += 1\n",
        "        for word, pos_tag in pos_tags:\n",
        "            word_counts[(word, pos_tag)] += 1\n",
        "\n",
        "    return word_counts, label_counts\n",
        "\n",
        "\n",
        "def train_hmm(word_counts, label_counts):\n",
        "    global initial_probs\n",
        "    global transition_probs\n",
        "    global emission_probs\n",
        "\n",
        "    total_labels = sum(label_counts.values())\n",
        "\n",
        "    for label, count in label_counts.items():\n",
        "        initial_probs[label] = count / total_labels\n",
        "\n",
        "    for word_pos, count in word_counts.items():\n",
        "        word, pos_tag = word_pos\n",
        "\n",
        "        for label in label_counts.keys():\n",
        "            transition_probs[label][word_pos] = count / label_counts[label]\n",
        "\n",
        "        total_emissions = sum(transition_probs[label].values())\n",
        "        for word_pos in transition_probs[label].keys():\n",
        "            emission_probs[label][word_pos] = transition_probs[label][word_pos] / total_emissions\n",
        "\n",
        "\n",
        "def viterbi(tweet, initial_probs, transition_probs, emission_probs):\n",
        "    if len(tweet) == 0:\n",
        "        return []\n",
        "\n",
        "    T = len(tweet)\n",
        "    N = len(sentiment_labels)\n",
        "\n",
        "    trellis = np.zeros((N, T))\n",
        "    backpointers = np.zeros((N, T), dtype=int)\n",
        "\n",
        "    for s in range(N):\n",
        "        trellis[s, 0] = initial_probs[sentiment_labels[s]] * emission_probs[sentiment_labels[s]][(tweet[0], pos_tag[0])]\n",
        "\n",
        "    for t in range(1, T):\n",
        "        for s in range(N):\n",
        "            max_prob = 0\n",
        "            max_state = 0\n",
        "            for prev_s in range(N):\n",
        "                prob = trellis[prev_s, t-1] * transition_probs[sentiment_labels[prev_s]][(tweet[t], pos_tag[t])] * \\\n",
        "                       emission_probs[sentiment_labels[s]][(tweet[t], pos_tag[t])]\n",
        "                if prob > max_prob:\n",
        "                    max_prob = prob\n",
        "                    max_state = prev_s\n",
        "            trellis[s, t] = max_prob\n",
        "            backpointers[s, t] = max_state\n",
        "\n",
        "    path = np.zeros(T, dtype=int)\n",
        "    path[T-1] = np.argmax(trellis[:, T-1])\n",
        "    for t in range(T-2, -1, -1):\n",
        "        path[t] = backpointers[path[t+1], t+1]\n",
        "\n",
        "    predicted_labels = [sentiment_labels[state] for state in path]\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "train_df = df.sample(frac=0.8, random_state=1)\n",
        "test_df = df.drop(train_df.index)\n",
        "word_counts, label_counts = preprocess_data(train_df)\n",
        "\n",
        "train_hmm(word_counts, label_counts)\n"
      ],
      "metadata": {
        "id": "l49ZHtlWRXHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_correct = 0\n",
        "num_total = 0\n",
        "\n",
        "for i, row in test_df.iterrows():\n",
        "    label, text = row['labels'], row['tokenized']\n",
        "\n",
        "    pos_tags = pt(text)\n",
        "\n",
        "    predicted_labels = viterbi(text, initial_probs, transition_probs, emission_probs)\n",
        "    if len(predicted_labels) > 0:\n",
        "        predicted_label = predicted_labels[-1]\n",
        "        if predicted_label == label:\n",
        "            num_correct += 1\n",
        "        num_total += 1\n",
        "\n",
        "accuracy = num_correct / num_total\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "wYlJo6o8et7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj_wnVr3BC-j"
      },
      "source": [
        "HIDDEN MARKOV MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lMHJq-zuQbd"
      },
      "source": [
        "HMM + biGRAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buqsFJ-P0e9T"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def preprocess_data(df):\n",
        "    word_counts = defaultdict(lambda: defaultdict(int))\n",
        "    label_counts = defaultdict(int)\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        label, text = row['labels'], row['tokenized']\n",
        "        label_counts[label] += 1\n",
        "        # words = text.split()\n",
        "        for j in range(len(text)-1):\n",
        "            word1, word2 = text[j], text[j+1]\n",
        "            word_counts[word1][word2] += 1\n",
        "\n",
        "    return word_counts, label_counts\n",
        "\n",
        "\n",
        "def train_hmm(word_counts, label_counts):\n",
        "    initial_probs = {}\n",
        "    transition_probs = {}\n",
        "    emission_probs = {}\n",
        "\n",
        "    total_labels = sum(label_counts.values())\n",
        "\n",
        "    for label, count in label_counts.items():\n",
        "        initial_probs[label] = count / total_labels\n",
        "\n",
        "    for word1 in word_counts.keys():\n",
        "        total_transitions = sum(word_counts[word1].values())\n",
        "        transition_probs[word1] = {}\n",
        "        for word2, count in word_counts[word1].items():\n",
        "            transition_probs[word1][word2] = count / total_transitions\n",
        "\n",
        "    for word1 in word_counts.keys():\n",
        "        total_emissions = sum(word_counts[word1].values())\n",
        "        emission_probs[word1] = {}\n",
        "        for word2, count in word_counts[word1].items():\n",
        "            emission_probs[word1][word2] = count / total_emissions\n",
        "\n",
        "    return initial_probs, transition_probs, emission_probs\n",
        "\n",
        "\n",
        "def predict_sentiment(tweet, initial_probs, transition_probs, emission_probs):\n",
        "    current_label_probs = initial_probs.copy()\n",
        "\n",
        "    for j in range(len(tweet)-1):\n",
        "        word1, word2 = tweet[j], tweet[j+1]\n",
        "        if word1 in transition_probs and word2 in emission_probs[word1]:\n",
        "            for label in current_label_probs.keys():\n",
        "                current_label_probs[label] *= transition_probs[word1][word2] * emission_probs[word1][word2]\n",
        "\n",
        "        total_prob = sum(current_label_probs.values())\n",
        "        if total_prob > 0:\n",
        "            for label in current_label_probs.keys():\n",
        "                current_label_probs[label] /= total_prob\n",
        "\n",
        "    predicted_label = max(current_label_probs, key=current_label_probs.get)\n",
        "    return predicted_label\n",
        "\n",
        "train_df = df.sample(frac=0.8, random_state=1)\n",
        "test_df = df.drop(train_df.index)\n",
        "\n",
        "word_counts, label_counts = preprocess_data(train_df)\n",
        "\n",
        "initial_probs, transition_probs, emission_probs = train_hmm(word_counts, label_counts)\n",
        "\n",
        "num_correct = 0\n",
        "num_total = 0\n",
        "\n",
        "for i, row in test_df.iterrows():\n",
        "    label, text = row['labels'], row['tokenized']\n",
        "    predicted_label = predict_sentiment(text, initial_probs, transition_probs, emission_probs)\n",
        "    if predicted_label == label:\n",
        "        num_correct += 1\n",
        "    num_total += 1\n",
        "\n",
        "accuracy = num_correct / num_total\n",
        "print(accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def preprocess_data(df):\n",
        "    word_counts = defaultdict(lambda: defaultdict(int))\n",
        "    label_counts = defaultdict(int)\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        label, text = row['labels'], row['tokenized']\n",
        "        label_counts[label] += 1\n",
        "        for j in range(len(text)-1):\n",
        "            word1, word2 = text[j], text[j+1]\n",
        "            word_counts[word1][word2] += 1\n",
        "\n",
        "    return word_counts, label_counts\n",
        "\n",
        "\n",
        "\n",
        "def train_hmm(word_counts, label_counts):\n",
        "    initial_probs = {}\n",
        "    transition_probs = {}\n",
        "    emission_probs = {}\n",
        "\n",
        "    total_labels = sum(label_counts.values())\n",
        "\n",
        "    for label, count in label_counts.items():\n",
        "        initial_probs[label] = count / total_labels\n",
        "\n",
        "    for word1 in word_counts.keys():\n",
        "        total_transitions = sum(word_counts[word1].values())\n",
        "        transition_probs[word1] = {}\n",
        "        for word2, count in word_counts[word1].items():\n",
        "            transition_probs[word1][word2] = count / total_transitions\n",
        "\n",
        "    for word1 in word_counts.keys():\n",
        "        emission_probs[word1] = {}\n",
        "        total_emissions = sum(word_counts[word1].values())\n",
        "        for word2, count in word_counts[word1].items():\n",
        "            emission_probs[word1][word2] = count / total_emissions\n",
        "\n",
        "    return initial_probs, transition_probs, emission_probs\n",
        "\n",
        "import math\n",
        "\n",
        "def predict_sentiment(tweet, initial_probs, transition_probs, emission_probs):\n",
        "    current_label_probs = initial_probs.copy()\n",
        "    log_prob_sum = math.log(sum(initial_probs.values()))\n",
        "\n",
        "    for j in range(len(tweet)-1):\n",
        "        word1, word2 = tweet[j], tweet[j+1]\n",
        "        if word1 in transition_probs and word2 in emission_probs[word1]:\n",
        "            new_label_probs = {}\n",
        "            for label in current_label_probs.keys():\n",
        "                transition_prob = transition_probs[word1][word2]\n",
        "                emission_prob = emission_probs[word1][word2]\n",
        "                log_prob = math.log(transition_prob) + math.log(emission_prob)\n",
        "                new_label_probs[label] = current_label_probs[label] + log_prob\n",
        "\n",
        "            max_log_prob = max(new_label_probs.values())\n",
        "            log_prob_sum = math.log(math.exp(log_prob_sum) + math.exp(max_log_prob))\n",
        "\n",
        "            for label in new_label_probs.keys():\n",
        "                new_label_probs[label] -= log_prob_sum\n",
        "\n",
        "            current_label_probs = new_label_probs\n",
        "\n",
        "    predicted_label = max(current_label_probs, key=current_label_probs.get)\n",
        "    return predicted_label\n",
        "\n",
        "\n",
        "\n",
        "train_df = df.sample(frac=0.8, random_state=1)\n",
        "test_df = df.drop(train_df.index)\n",
        "\n",
        "word_counts, label_counts = preprocess_data(train_df)\n",
        "\n",
        "initial_probs, transition_probs, emission_probs = train_hmm(word_counts, label_counts)\n",
        "\n",
        "num_correct = 0\n",
        "num_total = 0\n",
        "\n",
        "for i, row in test_df.iterrows():\n",
        "    label, text = row['labels'], row['tokenized']\n",
        "    predicted_label = predict_sentiment(text, initial_probs, transition_probs, emission_probs)\n",
        "    if predicted_label == label:\n",
        "        num_correct += 1\n",
        "    num_total += 1\n",
        "\n",
        "accuracy = num_correct / num_total\n",
        "print(accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN12ol0bGBdw",
        "outputId": "0f95c667-3463-4c25-d1d6-37d25d4ba9d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4932853006224492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_correct = 0\n",
        "num_total = 0\n",
        "p_labels = []\n",
        "for i, row in test_df.iterrows():\n",
        "    label, text = row['labels'], row['tokenized']\n",
        "    predicted_label = predict_sentiment(text, initial_probs, transition_probs, emission_probs)\n",
        "\n",
        "    if predicted_label == label:\n",
        "        num_correct += 1\n",
        "    num_total += 1\n",
        "    p_labels.append(predicted_label)\n",
        "\n",
        "print(set(p_labels))\n",
        "accuracy = num_correct / num_total\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16ut2xnwEh3D",
        "outputId": "35ae77e5-d705-484b-8b4b-ee2e53402cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bad'}\n",
            "0.4932853006224492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3Y1DlHIaI0y"
      },
      "source": [
        "HMM AND VITERBI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ggP7jvp1yeH",
        "outputId": "b025a6fb-d609-4269-822f-0c573e2d83ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.47707824658284465\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "sentiment_labels = ['good', 'bad', 'neutral' ]\n",
        "\n",
        "#\n",
        "def preprocess_data(df):\n",
        "    word_counts = defaultdict(int)\n",
        "    label_counts = defaultdict(int)\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        label, text = row['labels'], row['tokenized']\n",
        "        label_counts[label] += 1\n",
        "        for word in text:\n",
        "            word_counts[word] += 1\n",
        "    return word_counts, label_counts\n",
        "\n",
        "def train_hmm(word_counts, label_counts):\n",
        "    initial_probs = {}\n",
        "    transition_probs = defaultdict(lambda: defaultdict(int))\n",
        "    emission_probs = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    total_labels = sum(label_counts.values())\n",
        "\n",
        "    for label, count in label_counts.items():\n",
        "        initial_probs[label] = count / total_labels\n",
        "\n",
        "    for word in word_counts.keys():\n",
        "        for label in label_counts.keys():\n",
        "            transition_probs[label][word] = word_counts[word] / label_counts[label]\n",
        "\n",
        "    for label in label_counts.keys():\n",
        "        total_emissions = sum(transition_probs[label].values())\n",
        "        for word in transition_probs[label].keys():\n",
        "            emission_probs[label][word] = transition_probs[label][word] / total_emissions\n",
        "\n",
        "    return initial_probs, transition_probs, emission_probs\n",
        "\n",
        "\n",
        "def viterbi(tweet, initial_probs, transition_probs, emission_probs):\n",
        "    if len(tweet) == 0:\n",
        "        return []\n",
        "\n",
        "    T = len(tweet)\n",
        "    N = len(sentiment_labels)\n",
        "\n",
        "    trellis = np.zeros((N, T))\n",
        "    backpointers = np.zeros((N, T), dtype=int)\n",
        "\n",
        "    for s in range(N):\n",
        "        trellis[s, 0] = initial_probs[sentiment_labels[s]] * emission_probs[sentiment_labels[s]][tweet[0]]\n",
        "\n",
        "    for t in range(1, T):\n",
        "        for s in range(N):\n",
        "            max_prob = 0\n",
        "            max_state = 0\n",
        "            for prev_s in range(N):\n",
        "                prob = trellis[prev_s, t-1] * transition_probs[sentiment_labels[prev_s]][tweet[t]] * emission_probs[sentiment_labels[s]][tweet[t]]\n",
        "                if prob > max_prob:\n",
        "                    max_prob = prob\n",
        "                    max_state = prev_s\n",
        "            trellis[s, t] = max_prob\n",
        "            backpointers[s, t] = max_state\n",
        "\n",
        "    path = np.zeros(T, dtype=int)\n",
        "    path[T-1] = np.argmax(trellis[:, T-1])\n",
        "    for t in range(T-2, -1, -1):\n",
        "        path[t] = backpointers[path[t+1], t+1]\n",
        "\n",
        "    predicted_labels = [sentiment_labels[state] for state in path]\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "train_df = df.sample(frac=0.8, random_state=1)\n",
        "test_df = df.drop(train_df.index)\n",
        "word_counts, label_counts = preprocess_data(train_df)\n",
        "\n",
        "initial_probs, transition_probs, emission_probs = train_hmm(word_counts, label_counts)\n",
        "\n",
        "\n",
        "num_correct = 0\n",
        "num_total = 0\n",
        "ps = []\n",
        "ls = []\n",
        "for i, row in test_df.iterrows():\n",
        "    label, text = row['labels'], row['tokenized']\n",
        "    predicted_labels = viterbi(text, initial_probs, transition_probs, emission_probs)\n",
        "    if len(predicted_labels) > 0:\n",
        "        predicted_label = predicted_labels[-1]  # Use the last predicted label\n",
        "        if predicted_label == \"good\":\n",
        "          predicted_label = \"bad\"\n",
        "        elif predicted_label == \"bad\":\n",
        "          predicted_label = \"good\"\n",
        "        if predicted_label == label:\n",
        "            num_correct += 1\n",
        "        num_total += 1\n",
        "        ps.append(predicted_label)\n",
        "        ls.append(label)\n",
        "\n",
        "\n",
        "accuracy = num_correct / num_total\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(ps, label = 'predicted');\n",
        "plt.hist(ls, label = 'labels');\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "DsJy-acdKCoy",
        "outputId": "f1a3763d-dbb1-4e8c-ea49-3db719244063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6ac2775510>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMVrL8SpW0L4"
      },
      "source": [
        "NAIVE BAYES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfVrbO7FUzr5",
        "outputId": "8022b40f-1a05-4618-a238-4882cd2a851b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7423561868715657\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_df['joined'])\n",
        "X_test = vectorizer.transform(test_df['joined'])\n",
        "\n",
        "y_train = train_df['labels']\n",
        "y_test = test_df['labels']\n",
        "\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train, y_train)\n",
        "\n",
        "y_pred = naive_bayes.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j27gPGXaDt-"
      },
      "source": [
        "NEW DATA PREDICTION WITH NAIVE BAYES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpsjTLytUzox",
        "outputId": "1238093d-a182-4902-e73f-e7134c8d7394"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: good\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "X = df['joined']\n",
        "y = df['labels']\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X_vectorized = vectorizer.fit_transform(X)\n",
        "\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_vectorized, y)\n",
        "\n",
        "def preprocess_and_predict(tweet):\n",
        "    preprocessed_tweet = preprocessor(tweet)\n",
        "    tweet_vectorized = vectorizer.transform([preprocessed_tweet])\n",
        "    prediction = nb_model.predict(tweet_vectorized)[0]\n",
        "    return prediction\n",
        "\n",
        "# New data\n",
        "new_tweet = \"i don't know if i like it or not\"\n",
        "prediction = preprocess_and_predict(new_tweet)\n",
        "print(\"Prediction:\", prediction)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wubj0ECoqa5T"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUhuyMCuqZ8Z",
        "outputId": "003c767f-00e2-4b05-ff34-34292aaca041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Accuracy: 0.8475\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "X = df['joined']\n",
        "y = df['labels']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('svm', SVC(probability=False, kernel='linear'))])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"SVM Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KCxrB0IqjKf",
        "outputId": "b1b82485-9d77-4edb-c640-c28f886be3e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/svm_model.pkl']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#save the trained svm\n",
        "import joblib\n",
        "joblib.dump(pipeline, '/content/drive/MyDrive/svm_model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "my_stemmer = PorterStemmer()\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "num_reviews = df['tweets'].size\n",
        "nltk.download('punkt')\n",
        "\n",
        "def preprocessor(raw_review):\n",
        "    clean1 = re.sub(r'http\\S+', ' ', raw_review)\n",
        "    clean2 = re.sub(r'www\\S+', ' ', clean1)\n",
        "    clean3 = re.sub(r'@\\w+', ' ', clean2)\n",
        "    clean4 = re.sub(r'#\\w+', ' ', clean3)\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean4)\n",
        "    words = word_tokenize(letters_only.lower())\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    meaningful_words = [w for w in words if not w in stops]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in meaningful_words]\n",
        "    return \" \".join(lemmatized_words)\n",
        "    # return lemmatized_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mm5nxOXJdVJk",
        "outputId": "57b06e8a-717e-4bac-d83d-7b56a49a48e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHA7ohMMJHBp",
        "outputId": "07f26c2d-3b79-4693-ae21-82a76f96eef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: neutral\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "# Load the saved SVM model\n",
        "pipeline = joblib.load('/content/drive/MyDrive/svm_model.pkl')\n",
        "\n",
        "# New tweet to predict\n",
        "new_tweet = \"chatgpt is a good invention but also harmful for software developers' career\"\n",
        "\n",
        "preprocessed_tweet = preprocessor(new_tweet)\n",
        "prediction = pipeline.predict([preprocessed_tweet])\n",
        "print(\"Predicted label:\", prediction[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHqARgWfJnNf"
      },
      "source": [
        "RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjBwbjRIJc4T",
        "outputId": "2441fcb4-b752-4216-fe6b-2470b40976e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy: 0.8079299573633689\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "X = df['joined']\n",
        "y = df['labels']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "X_train_transformed = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_test_transformed = vectorizer.transform(X_test)\n",
        "\n",
        "rf_classifier = RandomForestClassifier()\n",
        "\n",
        "rf_classifier.fit(X_train_transformed, y_train)\n",
        "\n",
        "y_pred = rf_classifier.predict(X_test_transformed)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Random Forest Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inzxqopkJ-IP",
        "outputId": "8cf86809-4a4c-439a-b6aa-df9ba02dcad8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/rf_model.pkl']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#save rf model\n",
        "joblib.dump(pipeline, '/content/drive/MyDrive/rf_model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tq4vFCL-LqzK",
        "outputId": "72791fca-251d-4f96-c438-d85d1573cb47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted label: good\n"
          ]
        }
      ],
      "source": [
        "# Load the saved model\n",
        "pipeline = joblib.load('/content/drive/MyDrive/rf_model.pkl')\n",
        "\n",
        "# New tweet to predict\n",
        "new_tweet = \"chatgpt is awesome but I'm not sure if I should use it\"\n",
        "\n",
        "preprocessed_tweet = preprocessor(new_tweet)\n",
        "\n",
        "prediction = pipeline.predict([preprocessed_tweet])\n",
        "\n",
        "print(\"Predicted label:\", prediction[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4G4CX9jZIIb"
      },
      "source": [
        "RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0GHiI0KZbHq"
      },
      "outputs": [],
      "source": [
        "df['new_label'] = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uem6LfA6Zg7y"
      },
      "outputs": [],
      "source": [
        "for i in df.index:\n",
        "    if df.labels[i] == 'bad' :\n",
        "        df.loc[i, 'new_label'] = 0\n",
        "    elif df.labels[i] == 'neutral':\n",
        "        df.loc[i, 'new_label'] = 1\n",
        "    elif df.labels[i] == 'good':\n",
        "        df.loc[i, 'new_label'] = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BILtbMxZaEP4",
        "outputId": "9a1e6011-c5f9-4340-86de-ef618e852ccc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b28fcb3f-2afe-41d7-a6c6-41da48d5f4b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "      <th>joined</th>\n",
              "      <th>new_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>chatgpt optimizing language model dialogue</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Try talking with ChatGPT, our new AI system wh...</td>\n",
              "      <td>good</td>\n",
              "      <td>try talking chatgpt new ai system optimized di...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>chatgpt optimizing language model dialogue n n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>THRILLED to share that ChatGPT, our new model ...</td>\n",
              "      <td>good</td>\n",
              "      <td>thrilled share chatgpt new model optimized dia...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>As of 2 minutes ago, @OpenAI released their ne...</td>\n",
              "      <td>bad</td>\n",
              "      <td>minute ago released new chatgpt n nand use right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b28fcb3f-2afe-41d7-a6c6-41da48d5f4b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b28fcb3f-2afe-41d7-a6c6-41da48d5f4b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b28fcb3f-2afe-41d7-a6c6-41da48d5f4b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0                                             tweets   labels  \\\n",
              "0           0  ChatGPT: Optimizing Language Models for Dialog...  neutral   \n",
              "1           1  Try talking with ChatGPT, our new AI system wh...     good   \n",
              "2           2  ChatGPT: Optimizing Language Models for Dialog...  neutral   \n",
              "3           3  THRILLED to share that ChatGPT, our new model ...     good   \n",
              "4           4  As of 2 minutes ago, @OpenAI released their ne...      bad   \n",
              "\n",
              "                                              joined new_label  \n",
              "0         chatgpt optimizing language model dialogue         1  \n",
              "1  try talking chatgpt new ai system optimized di...         2  \n",
              "2  chatgpt optimizing language model dialogue n n...         1  \n",
              "3  thrilled share chatgpt new model optimized dia...         2  \n",
              "4   minute ago released new chatgpt n nand use right         0  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDWsLCDFY8jq",
        "outputId": "a6ea8c72-021d-44d5-a6e1-7ddd60d2bbe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "5483/5483 [==============================] - 76s 13ms/step - loss: -55.6008 - accuracy: 0.5376 - val_loss: -123.1615 - val_accuracy: 0.5803\n",
            "Epoch 2/10\n",
            "5483/5483 [==============================] - 44s 8ms/step - loss: -171.6275 - accuracy: 0.5350 - val_loss: -250.1013 - val_accuracy: 0.5990\n",
            "Epoch 3/10\n",
            "5483/5483 [==============================] - 45s 8ms/step - loss: -316.7724 - accuracy: 0.5897 - val_loss: -375.1447 - val_accuracy: 0.5720\n",
            "Epoch 4/10\n",
            "5483/5483 [==============================] - 43s 8ms/step - loss: -475.8191 - accuracy: 0.6159 - val_loss: -541.7548 - val_accuracy: 0.6279\n",
            "Epoch 5/10\n",
            "5483/5483 [==============================] - 44s 8ms/step - loss: -637.2718 - accuracy: 0.6361 - val_loss: -716.8143 - val_accuracy: 0.6463\n",
            "Epoch 6/10\n",
            "5483/5483 [==============================] - 45s 8ms/step - loss: -819.2163 - accuracy: 0.6533 - val_loss: -847.2174 - val_accuracy: 0.6527\n",
            "Epoch 7/10\n",
            "5483/5483 [==============================] - 42s 8ms/step - loss: -997.9658 - accuracy: 0.6711 - val_loss: -1036.0951 - val_accuracy: 0.6579\n",
            "Epoch 8/10\n",
            "5483/5483 [==============================] - 42s 8ms/step - loss: -1165.1669 - accuracy: 0.6782 - val_loss: -1193.7235 - val_accuracy: 0.6644\n",
            "Epoch 9/10\n",
            "5483/5483 [==============================] - 43s 8ms/step - loss: -1329.1543 - accuracy: 0.6829 - val_loss: -1334.4958 - val_accuracy: 0.6541\n",
            "Epoch 10/10\n",
            "5483/5483 [==============================] - 43s 8ms/step - loss: -1505.0073 - accuracy: 0.6892 - val_loss: -1501.9153 - val_accuracy: 0.6584\n",
            "1371/1371 [==============================] - 4s 3ms/step\n",
            "RNN Accuracy: 0.6584281447365421\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "X = df['joined']\n",
        "y = df['new_label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_tokens = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "max_sequence_length = max([len(tokens) for tokens in X_train_tokens])\n",
        "X_train_padded = pad_sequences(X_train_tokens, maxlen=max_sequence_length, padding='post')\n",
        "X_test_padded = pad_sequences(X_test_tokens, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "X_train_padded = tf.convert_to_tensor(X_train_padded, dtype=tf.int32)\n",
        "X_test_padded = tf.convert_to_tensor(X_test_padded, dtype=tf.int32)\n",
        "y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
        "y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(tokenizer.word_index) + 1, 100, input_length=max_sequence_length))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_padded, y_train, validation_data=(X_test_padded, y_test), epochs=10, batch_size=32)\n",
        "\n",
        "y_pred_prob = model.predict(X_test_padded)\n",
        "y_pred = np.round(y_pred_prob).astype(int)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"RNN Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XVjQDtYYrLg"
      },
      "outputs": [],
      "source": [
        "#save rnn model\n",
        "model.save('/content/drive/MyDrive/rnn_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeYPn3lrYp8A",
        "outputId": "fcc90bae-8889-45ab-cdbf-723b90d9d076"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 545ms/step\n",
            "Predicted Label: bad\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('/content/drive/MyDrive/rnn_model.h5')\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "max_sequence_length = max([len(tokens) for tokens in X_train_tokens])\n",
        "\n",
        "def preprocess_tweet(tweet):\n",
        "    tokens = tokenizer.texts_to_sequences([tweet])\n",
        "    padded_sequence = pad_sequences(tokens, maxlen=max_sequence_length)\n",
        "    return padded_sequence\n",
        "\n",
        "# New tweet to predict\n",
        "new_tweet = \"i don't know if i like it\"\n",
        "\n",
        "preprocessed_tweet = preprocess_tweet(new_tweet)\n",
        "\n",
        "predictions = model.predict(preprocessed_tweet)\n",
        "predicted_label = tf.argmax(predictions, axis=1).numpy()[0]\n",
        "\n",
        "if predicted_label == 0:\n",
        "  predicted_label = 'bad'\n",
        "elif predicted_label == 1:\n",
        "  predicted_label = 'neutral'\n",
        "elif predicted_label == 2:\n",
        "  predicted_label = 'good'\n",
        "\n",
        "print(\"Predicted Label:\", predicted_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwQMNYYJh6Sm"
      },
      "source": [
        "CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmWpzwALhjz1",
        "outputId": "a7cff0cf-305f-4e64-86fd-0b17b5747198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "5483/5483 [==============================] - 70s 12ms/step - loss: -92619.0469 - accuracy: 0.5026 - val_loss: -324672.5000 - val_accuracy: 0.5224\n",
            "Epoch 2/10\n",
            "5483/5483 [==============================] - 36s 7ms/step - loss: -961455.7500 - accuracy: 0.5181 - val_loss: -1813087.2500 - val_accuracy: 0.5099\n",
            "Epoch 3/10\n",
            "5483/5483 [==============================] - 33s 6ms/step - loss: -3302530.7500 - accuracy: 0.5208 - val_loss: -5032567.0000 - val_accuracy: 0.5171\n",
            "Epoch 4/10\n",
            "5483/5483 [==============================] - 32s 6ms/step - loss: -7697423.5000 - accuracy: 0.5221 - val_loss: -10568711.0000 - val_accuracy: 0.5162\n",
            "Epoch 5/10\n",
            "5483/5483 [==============================] - 31s 6ms/step - loss: -14726738.0000 - accuracy: 0.5222 - val_loss: -18960358.0000 - val_accuracy: 0.5147\n",
            "Epoch 6/10\n",
            "5483/5483 [==============================] - 32s 6ms/step - loss: -24940060.0000 - accuracy: 0.5214 - val_loss: -30762702.0000 - val_accuracy: 0.5186\n",
            "Epoch 7/10\n",
            "5483/5483 [==============================] - 32s 6ms/step - loss: -38958236.0000 - accuracy: 0.5218 - val_loss: -46545472.0000 - val_accuracy: 0.5119\n",
            "Epoch 8/10\n",
            "5483/5483 [==============================] - 31s 6ms/step - loss: -57216072.0000 - accuracy: 0.5221 - val_loss: -66840900.0000 - val_accuracy: 0.5127\n",
            "Epoch 9/10\n",
            "5483/5483 [==============================] - 32s 6ms/step - loss: -80374264.0000 - accuracy: 0.5214 - val_loss: -92190432.0000 - val_accuracy: 0.5117\n",
            "Epoch 10/10\n",
            "5483/5483 [==============================] - 32s 6ms/step - loss: -108960192.0000 - accuracy: 0.5217 - val_loss: -123096040.0000 - val_accuracy: 0.5074\n",
            "1371/1371 [==============================] - 2s 1ms/step\n",
            "CNN Accuracy: 0.5074443101757906\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X = df['joined']\n",
        "y = df['new_label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_tokens = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "\n",
        "max_sequence_length = max([len(tokens) for tokens in X_train_tokens])\n",
        "X_train_padded = pad_sequences(X_train_tokens, maxlen=max_sequence_length, padding='post')\n",
        "X_test_padded = pad_sequences(X_test_tokens, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "X_train_padded = tf.convert_to_tensor(X_train_padded, dtype=tf.int32)\n",
        "X_test_padded = tf.convert_to_tensor(X_test_padded, dtype=tf.int32)\n",
        "y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
        "y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(tokenizer.word_index) + 1, 100, input_length=max_sequence_length))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_padded, y_train, validation_data=(X_test_padded, y_test), epochs=10, batch_size=32)\n",
        "\n",
        "y_pred_prob = model.predict(X_test_padded)\n",
        "y_pred = np.round(y_pred_prob).astype(int)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"CNN Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDfKN_Kqg1sb"
      },
      "outputs": [],
      "source": [
        "#save cnn model\n",
        "model.save('/content/drive/MyDrive/cnn_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX2RKwrbj6Gl",
        "outputId": "db840c4c-b4b1-4174-c6fb-d968cf1621e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 126ms/step\n",
            "Predicted Label: bad\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('/content/drive/MyDrive/cnn_model.h5')\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "max_sequence_length = max([len(tokens) for tokens in X_train_tokens])\n",
        "\n",
        "def preprocess_tweet(tweet):\n",
        "    tokens = tokenizer.texts_to_sequences([tweet])\n",
        "    padded_sequence = pad_sequences(tokens, maxlen=max_sequence_length)\n",
        "    return padded_sequence\n",
        "\n",
        "# New tweet to predict\n",
        "new_tweet = \"i love it\"\n",
        "\n",
        "preprocessed_tweet = preprocess_tweet(new_tweet)\n",
        "\n",
        "predictions = model.predict(preprocessed_tweet)\n",
        "predicted_label = tf.argmax(predictions, axis=1).numpy()[0]\n",
        "\n",
        "if predicted_label == 0:\n",
        "  predicted_label = 'bad'\n",
        "elif predicted_label == 1:\n",
        "  predicted_label = 'neutral'\n",
        "elif predicted_label == 2:\n",
        "  predicted_label = 'good'\n",
        "\n",
        "print(\"Predicted Label:\", predicted_label)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}